{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s2hUGHhMYLq"
      },
      "source": [
        "# BERT-Based Aspect-Based Sentiment Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIAkBi-MMu4m"
      },
      "source": [
        "# Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7k0hC1rTdVi"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "#pip install -q transformers\n",
        "!pip install --upgrade pip\n",
        "!pip install transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "\n",
        "# Setting up the device for GPU usage if available\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "## Stemming algorithm (Not Used)\n",
        "#from nltk.stem import PorterStemmer\n",
        "#from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "#ps = PorterStemmer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrigrSjTZg3L"
      },
      "source": [
        "# Importing and Pre-Processing the Twitter Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc12ki90UG5Y"
      },
      "outputs": [],
      "source": [
        "# Function used to clean text from non-alphabetical characters excluding spaces\n",
        "def cleanText(text):\n",
        "  # Remove specific substrings '(' and ')'\n",
        "  text = text.replace('-LRB-', '').replace('-RRB-', '')\n",
        "  # Remove non-alphabetical characters\n",
        "  cleaned_text = ''.join(letter for letter in text if letter.isalpha() or letter.isspace())\n",
        "\n",
        "  ## Stem the words with the stemming algorithm (Not Used)\n",
        "  #words = word_tokenize(cleaned_text)\n",
        "  #stemmed_words = [ps.stem(w) for w in words]\n",
        "  #stemmed_sentence = ' '.join(stemmed_words)\n",
        "  #return(stemmed_sentence)\n",
        "\n",
        "  return(cleaned_text)\n",
        "\n",
        "\n",
        "# Function used to convert the original datset into a concatenated dataframe\n",
        "def fixDataFormat(df):\n",
        "  tweet = []\n",
        "  target = []\n",
        "  classification = []\n",
        "\n",
        "  # Convert the three lines into their respective list\n",
        "  for i in range(df.shape[0]):\n",
        "    if (i%3 == 0):                            # First line is the tweet\n",
        "      tweet.append(df.iloc[i].tolist()[0])\n",
        "    elif (i%3 == 1):                          # Second line is the target\n",
        "      target.append(df.iloc[i].tolist()[0])\n",
        "    elif (i%3 == 2):                          # Third line is the classification\n",
        "      classification.append(df.iloc[i].tolist()[0])\n",
        "\n",
        "  # Convert the classification into a one-hot-encoding using get_dummies\n",
        "  temp_df = pd.DataFrame({'classification': classification})\n",
        "  one_hot_encoding = pd.get_dummies(temp_df['classification'])\n",
        "  one_hot_list = one_hot_encoding.values.tolist()\n",
        "\n",
        "  # Iterate over the indices of 'tweet' and replace \"$T$\" with the corresponding\n",
        "  # 'target' word, and concatenate 'tweet' and 'target' using [SEP] token\n",
        "  final_tweet = []\n",
        "  for i in range(len(tweet)):\n",
        "    replaced_tweet = tweet[i].replace(\"$T$\", target[i])\n",
        "    replaced_tweet = f\"{cleanText(replaced_tweet)} [SEP] {cleanText(target[i])}\"\n",
        "    final_tweet.append(replaced_tweet)\n",
        "\n",
        "  # Create the final dataframe\n",
        "  new_df = pd.DataFrame({\n",
        "      'tweet': final_tweet,\n",
        "      'sentiment': one_hot_list\n",
        "  })\n",
        "\n",
        "  return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8jxaFlXO09S"
      },
      "outputs": [],
      "source": [
        "# Read the training/testing dataset and convert a final DataFrame\n",
        "df_train = pd.read_csv('train.raw', sep='\\t', header=None, names=['data'])\n",
        "df_test = pd.read_csv('test.raw', sep='\\t', header=None, names=['data'])\n",
        "train_dataset = fixDataFormat(df_train)\n",
        "test_dataset = fixDataFormat(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujImvQQogVtc"
      },
      "outputs": [],
      "source": [
        "# Print the first 5 indexes of the training data\n",
        "train_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vMfFj6zgWIk"
      },
      "outputs": [],
      "source": [
        "# Print the first 5 indexes of the testing data\n",
        "test_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqS_rRGXZpIF"
      },
      "source": [
        "# Preparing the Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXhhFiX9Zv1i"
      },
      "outputs": [],
      "source": [
        "# Defining some key variables that will be used later on in the training\n",
        "# for the pre-trained BERT model by Hugging Face\n",
        "MAX_LEN = 200\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 1e-12\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFABf-Z4fC0C"
      },
      "outputs": [],
      "source": [
        "# Create a Dataset class to be passed to the model\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.tweet = dataframe.tweet\n",
        "        self.targets = self.data.sentiment\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tweet)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        tweet = str(self.tweet[index])\n",
        "        tweet = \" \".join(tweet.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            tweet,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',  # Use this instead of pad_to_max_length=True\n",
        "            truncation=True,  # Add this line to explicitly activate truncation\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AR0z6-8f6FF"
      },
      "outputs": [],
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xc7vWt3k0fS"
      },
      "outputs": [],
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqbPcCqTk8Iy"
      },
      "source": [
        "# Creating the Neural Network for Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J11OwIBXk9Kz"
      },
      "outputs": [],
      "source": [
        "# Creating the customized BERT-based model by HuggingFace, by adding a drop out\n",
        "# and a dense layer on top of BERT to get the final output for the model\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 3)   # 3 classes: negative, neutral, positive\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
        "        output_2 = self.l2(output_1)\n",
        "        output = self.l3(output_2)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ngs8g6fgkxTj"
      },
      "outputs": [],
      "source": [
        "model = BERTClass()   # Pretrained BERT-based model by HuggingFace\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLZqOlvFmIkO"
      },
      "outputs": [],
      "source": [
        "# Assigning the loss and optimizer functions\n",
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrxdxPDAmOVk"
      },
      "source": [
        "# Fine Tuning the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVF2c5DJmP_-"
      },
      "outputs": [],
      "source": [
        "# Function used to train and optimize the BERT model\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for i,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if i%156==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvyk1OSQnSHg"
      },
      "outputs": [],
      "source": [
        "# Function used to evaluate the current model\n",
        "def validation():\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53ErR-_3mWXN"
      },
      "outputs": [],
      "source": [
        "# For each epoch:\n",
        "#for epoch in range(EPOCHS):\n",
        "for epoch in range(10, 20):\n",
        "    # Train the model\n",
        "    train(epoch)\n",
        "\n",
        "    # Predict the output and set the class with the highest value\n",
        "    outputs, targets = validation()\n",
        "    outputs_array = np.array(outputs)\n",
        "    # Find the index of the maximum value for each item\n",
        "    max_indices = np.argmax(outputs_array, axis=1)\n",
        "    # Create a boolean array where only the maximum value for each item is True\n",
        "    result = np.zeros_like(outputs_array, dtype=bool)\n",
        "    result[np.arange(len(outputs_array)), max_indices] = True\n",
        "\n",
        "    # Evaluate the model and print the results\n",
        "    accuracy = metrics.accuracy_score(targets, result)\n",
        "    f1_score_macro = metrics.f1_score(targets, result, average='macro')\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
        "\n",
        "    # Save the model after each epoch\n",
        "    torch.save(model, \"model\" + str(epoch) + \".pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojtnWj9HSpPd"
      },
      "source": [
        "# Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg9GlOzcSuv6"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model_save_path = \"model.pth\"\n",
        "torch.save(model, model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzBowfa3lGoS"
      },
      "source": [
        "# Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPYQ-bc1TkZs"
      },
      "outputs": [],
      "source": [
        "# Load model and tokenizer\n",
        "#loaded_model = BERTClass()\n",
        "loaded_model_path = \"model.pth\"\n",
        "loaded_model = torch.load(loaded_model_path)\n",
        "\n",
        "loaded_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TgEaStQT6j9"
      },
      "outputs": [],
      "source": [
        "# Function used to evaluate the current model\n",
        "def loaded_validation():\n",
        "    loaded_model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype=torch.long)\n",
        "            mask = data['mask'].to(device, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype=torch.float)\n",
        "\n",
        "            # Move loaded_model to GPU if available. Must be the save device as previous\n",
        "            loaded_model_to_device = loaded_model.to(device)\n",
        "\n",
        "            outputs = loaded_model_to_device(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "    return fin_outputs, fin_targets\n",
        "\n",
        "\n",
        "# Predict the output and set the class with the highest value\n",
        "outputs, targets = loaded_validation()\n",
        "outputs_array = np.array(outputs)\n",
        "# Find the index of the maximum value for each item\n",
        "max_indices = np.argmax(outputs_array, axis=1)\n",
        "# Create a boolean array where only the maximum value for each item is True\n",
        "result = np.zeros_like(outputs_array, dtype=bool)\n",
        "result[np.arange(len(outputs_array)), max_indices] = True\n",
        "\n",
        "# Evaluate the model and print the results\n",
        "accuracy = metrics.accuracy_score(targets, result)\n",
        "f1_score_macro = metrics.f1_score(targets, result, average='macro')\n",
        "print(f\"Accuracy Score = {accuracy}\")\n",
        "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}